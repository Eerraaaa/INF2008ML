{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the following dependencies (pip install)\n",
    "# datasets\n",
    "# seaborn\n",
    "# scikit-learn\n",
    "# kagglehub\n",
    "# opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the IAM (human handwriting dataset) from kaggle. <br>\n",
    "Download the Deepwriting (ai handwriting dataset) from https://ait.ethz.ch/deepwriting choose the dataset, then unzip the file and just use the .npz file <br>\n",
    "\n",
    "OR DOWNLOAD AND UNZIP FROM THE GOOGLE DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Carine\\.cache\\kagglehub\\datasets\\naderabdalghani\\iam-handwritten-forms-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# download the IAM (human handwriting dataset) SKIP IF ALREADY HAVE THE DATASET\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"naderabdalghani/iam-handwritten-forms-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START\n",
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 34577 images and saved to C:\\Users\\Carine\\Desktop\\deepwriting_train\n",
      "Processed 705 images and saved to C:\\Users\\Carine\\Desktop\\deepwriting_val\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Process Both DeepWriting Training & Validation Datasets\n",
    "\n",
    "# Paths to DeepWriting datasets\n",
    "deepwriting_train_path = r\"C:\\Users\\Carine\\Desktop\\deepwriting_training.npz\" # CHANGE TO YOUR PATH\n",
    "deepwriting_val_path = r\"C:\\Users\\Carine\\Desktop\\deepwriting_validation.npz\" # CHANGE TO YOUR PATH\n",
    "\n",
    "# Output folders for processed images\n",
    "train_output_path = r\"C:\\Users\\Carine\\Desktop\\deepwriting_train\" # CHANGE TO YOUR PATH\n",
    "val_output_path = r\"C:\\Users\\Carine\\Desktop\\deepwriting_val\" # CHANGE TO YOUR PATH\n",
    "os.makedirs(train_output_path, exist_ok=True)\n",
    "os.makedirs(val_output_path, exist_ok=True)\n",
    "\n",
    "# Function to load, convert strokes to images, and save them\n",
    "def process_deepwriting(npz_path, output_folder):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    strokes = data[\"strokes\"]  # Extract stroke sequences\n",
    "\n",
    "    def strokes_to_image(stroke_data, img_size=128):\n",
    "        x = np.cumsum(stroke_data[:, 0])\n",
    "        y = np.cumsum(stroke_data[:, 1])\n",
    "\n",
    "        x = ((x - x.min()) / (x.max() - x.min()) * (img_size - 1)).astype(np.int32)\n",
    "        y = ((y - y.min()) / (y.max() - y.min()) * (img_size - 1)).astype(np.int32)\n",
    "\n",
    "        img = np.ones((img_size, img_size), dtype=np.uint8) * 255  # White background\n",
    "\n",
    "        for i in range(len(x) - 1):\n",
    "            cv2.line(img, (x[i], y[i]), (x[i+1], y[i+1]), 0, thickness=2)\n",
    "\n",
    "        return img\n",
    "\n",
    "    for idx, stroke_data in enumerate(strokes):\n",
    "        img = strokes_to_image(stroke_data)\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"deepwriting_{idx}.png\"), img)\n",
    "\n",
    "    print(f\"Processed {len(strokes)} images and saved to {output_folder}\")\n",
    "\n",
    "# Process training and validation datasets\n",
    "process_deepwriting(deepwriting_train_path, train_output_path)\n",
    "process_deepwriting(deepwriting_val_path, val_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM Dataset Loaded: (1539, 128, 128), Labels: (1539,)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Process IAM (Human Handwriting) Dataset\n",
    "\n",
    "# **Updated IAM dataset path**\n",
    "iam_dataset_path = r\"C:\\Users\\Carine\\.cache\\kagglehub\\datasets\\naderabdalghani\\iam-handwritten-forms-dataset\\versions\\1\\data\" # CHANGE TO YOUR PATH\n",
    "\n",
    "# Function to load images recursively from all subfolders\n",
    "def load_images_from_subfolders(parent_folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # **Loop through each subfolder**\n",
    "    for subfolder in os.listdir(parent_folder):\n",
    "        subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "        \n",
    "        # Ensure it's a folder\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue  \n",
    "\n",
    "        # **Process all images inside the subfolder**\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if file.endswith(\".png\") or file.endswith(\".jpg\"):  # Process only images\n",
    "                img_path = os.path.join(subfolder_path, file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "                \n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read image {file} in {subfolder}\")\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.resize(img, (128, 128)) / 255.0  # Resize and normalize\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# **Load IAM dataset again (including subfolders)**\n",
    "iam_images, iam_labels = load_images_from_subfolders(iam_dataset_path, label=0)\n",
    "\n",
    "# **Check if images are loaded**\n",
    "print(f\"IAM Dataset Loaded: {iam_images.shape}, Labels: {iam_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWriting Train Shape: (34577, 128, 128), Labels: (34577,)\n",
      "DeepWriting Validation Shape: (705, 128, 128), Labels: (705,)\n",
      "Final dataset saved with training shape (35808, 128, 128), validation shape (1013, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Merge IAM & DeepWriting Datasets\n",
    "\n",
    "# **Ensure IAM images have the correct shape**\n",
    "iam_images = iam_images.reshape(-1, 128, 128)\n",
    "\n",
    "# **Load DeepWriting Images**\n",
    "deepwriting_train_path = r\"C:\\Users\\Carine\\Desktop\\deepwriting_train\" # CHANGE TO YOUR PATH\n",
    "deepwriting_val_path = r\"C:\\Users\\Carine\\Desktop\\deepwriting_val\" # CHANGE TO YOUR PATH\n",
    "\n",
    "# Function to load images from folder\n",
    "def load_images_from_folder(folder_path, label):\n",
    "    images, labels = [], []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = img / 255.0  # Normalize\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "deepwriting_train_images, deepwriting_train_labels = load_images_from_folder(deepwriting_train_path, label=1)\n",
    "deepwriting_val_images, deepwriting_val_labels = load_images_from_folder(deepwriting_val_path, label=1)\n",
    "\n",
    "# **Check DeepWriting Shapes**\n",
    "print(f\"DeepWriting Train Shape: {deepwriting_train_images.shape}, Labels: {deepwriting_train_labels.shape}\")\n",
    "print(f\"DeepWriting Validation Shape: {deepwriting_val_images.shape}, Labels: {deepwriting_val_labels.shape}\")\n",
    "\n",
    "# **Split IAM dataset into 80% train and 20% validation**\n",
    "split_idx = int(0.8 * len(iam_images))\n",
    "iam_train_images, iam_train_labels = iam_images[:split_idx], iam_labels[:split_idx]\n",
    "iam_val_images, iam_val_labels = iam_images[split_idx:], iam_labels[split_idx:]\n",
    "\n",
    "# **Merge AI (DeepWriting) & Human (IAM) datasets**\n",
    "X_train = np.concatenate((deepwriting_train_images, iam_train_images), axis=0)\n",
    "y_train = np.concatenate((deepwriting_train_labels, iam_train_labels), axis=0)\n",
    "X_val = np.concatenate((deepwriting_val_images, iam_val_images), axis=0)\n",
    "y_val = np.concatenate((deepwriting_val_labels, iam_val_labels), axis=0)\n",
    "\n",
    "# **Shuffle dataset**\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=42)\n",
    "\n",
    "# **Save the final dataset**\n",
    "dataset_path = r\"C:\\Users\\Carine\\Desktop\\preprocessed_handwriting_dataset.npz\" # CHANGE TO YOUR PATH\n",
    "np.savez(dataset_path, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "print(f\"Final dataset saved with training shape {X_train.shape}, validation shape {X_val.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
